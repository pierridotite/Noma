{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd9dbd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The noma_magic extension is already loaded. To reload it, use:\n",
      "  %reload_ext noma_magic\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/workspaces/NOMA/notebook')\n",
    "%load_ext noma_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41bf8f0",
   "metadata": {},
   "source": [
    "## 1. Activation Functions\n",
    "\n",
    "Define common activation functions used in neural networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e8cf59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='background:#f5f5f5; padding:10px; border-radius:5px; color:#000;'>Running: /home/codespace/.noma_jupyter/workspace/cell_0_acc65c92e0aba0be.noma\n",
       "[print] 0.6224593312018546\n",
       "[print] 0.6224593312018546\n",
       "[print] 0.5\n",
       "[print] 0.6224593312018546\n",
       "[print] 0.5\n",
       "[print] 0.5\n",
       "[print] 0.4621171572600098\n",
       "Result: 0\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Running: /home/codespace/.noma_jupyter/workspace/cell_0_acc65c92e0aba0be.noma\\n[print] 0.6224593312018546\\n[print] 0.6224593312018546\\n[print] 0.5\\n[print] 0.6224593312018546\\n[print] 0.5\\n[print] 0.5\\n[print] 0.4621171572600098\\nResult: 0\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%noma\n",
    "fn sigmoid(x) {\n",
    "    return 1.0 / (1.0 + exp(-x));\n",
    "}\n",
    "\n",
    "fn relu(x) {\n",
    "    if (x > 0.0) { \n",
    "        return x;\n",
    "    } else { \n",
    "        return 0.0;\n",
    "    }\n",
    "}\n",
    "\n",
    "fn leaky_relu(x) {\n",
    "    let alpha = 0.01;\n",
    "    if (x > 0.0) { \n",
    "        return x;\n",
    "    } else { \n",
    "        return alpha * x;\n",
    "    }\n",
    "}\n",
    "\n",
    "fn tanh_act(x) {\n",
    "    let ex = exp(x);\n",
    "    let emx = exp(-x);\n",
    "    return (ex - emx) / (ex + emx);\n",
    "}\n",
    "\n",
    "fn main() {\n",
    "    let test_val = 0.5;\n",
    "    \n",
    "    // sigmoid(0.5)\n",
    "    print(sigmoid(test_val));\n",
    "    // relu(0.5)\n",
    "    print(relu(test_val));\n",
    "    // leaky_relu(0.5)\n",
    "    print(leaky_relu(test_val));\n",
    "    // tanh(0.5)\n",
    "    print(tanh_act(test_val));\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7fcc8b",
   "metadata": {},
   "source": [
    "## 2. Simple Neural Network Layer\n",
    "\n",
    "Implement a single dense layer with forward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7e36925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='background:#f5f5f5; padding:10px; border-radius:5px; color:#000;'>Running: /home/codespace/.noma_jupyter/workspace/cell_1_ae2f54ce1591b98a.noma\n",
       "[print] 0.679178699175393\n",
       "Result: 0\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Running: /home/codespace/.noma_jupyter/workspace/cell_1_ae2f54ce1591b98a.noma\\n[print] 0.679178699175393\\nResult: 0\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%noma\n",
    "fn sigmoid(x) { \n",
    "    return 1.0 / (1.0 + exp(-x));\n",
    "}\n",
    "\n",
    "fn forward_layer(x1, x2, w1, w2, bias) {\n",
    "    let z = x1 * w1 + x2 * w2 + bias;\n",
    "    return sigmoid(z);\n",
    "}\n",
    "\n",
    "fn main() {\n",
    "    let w1 = 0.5;\n",
    "    let w2 = 0.3;\n",
    "    let b = 0.1;\n",
    "    \n",
    "    let x1 = 1.0;\n",
    "    let x2 = 0.5;\n",
    "    \n",
    "    let output = forward_layer(x1, x2, w1, w2, b);\n",
    "    \n",
    "    // Single layer output\n",
    "    print(output);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf3fa0c",
   "metadata": {},
   "source": [
    "## 3. Multi-Layer Network\n",
    "\n",
    "Build a 2-layer neural network (2 → 3 → 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62f02fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='background:#f5f5f5; padding:10px; border-radius:5px; color:#000;'>Running: /home/codespace/.noma_jupyter/workspace/cell_2_2debce2712989304.noma\n",
       "[print] 0.7\n",
       "[print] 0\n",
       "[print] 0.9000000000000001\n",
       "[print] 0.8099984339846871\n",
       "Result: 0\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Running: /home/codespace/.noma_jupyter/workspace/cell_2_2debce2712989304.noma\\n[print] 0.7\\n[print] 0\\n[print] 0.9000000000000001\\n[print] 0.8099984339846871\\nResult: 0\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%noma\n",
    "fn relu(x) { \n",
    "    if (x > 0.0) { \n",
    "        return x;\n",
    "    } else { \n",
    "        return 0.0;\n",
    "    }\n",
    "}\n",
    "\n",
    "fn sigmoid(x) { \n",
    "    return 1.0 / (1.0 + exp(-x));\n",
    "}\n",
    "\n",
    "fn main() {\n",
    "    // Layer 1: 2 inputs -> 3 hidden neurons\n",
    "    let w1_11 = 0.5;\n",
    "    let w1_12 = -0.3;\n",
    "    let w1_13 = 0.8;\n",
    "    let w1_21 = 0.2;\n",
    "    let w1_22 = 0.6;\n",
    "    let w1_23 = -0.4;\n",
    "    \n",
    "    let b1_1 = 0.1;\n",
    "    let b1_2 = -0.2;\n",
    "    let b1_3 = 0.3;\n",
    "    \n",
    "    // Layer 2: 3 hidden -> 1 output\n",
    "    let w2_1 = 0.7;\n",
    "    let w2_2 = -0.5;\n",
    "    let w2_3 = 0.9;\n",
    "    let b2 = 0.15;\n",
    "    \n",
    "    // Forward pass\n",
    "    let x1 = 1.0;\n",
    "    let x2 = 0.5;\n",
    "    \n",
    "    // Hidden layer computation\n",
    "    let h1_z = x1 * w1_11 + x2 * w1_21 + b1_1;\n",
    "    let h2_z = x1 * w1_12 + x2 * w1_22 + b1_2;\n",
    "    let h3_z = x1 * w1_13 + x2 * w1_23 + b1_3;\n",
    "    \n",
    "    // Apply ReLU activation\n",
    "    let h1 = relu(h1_z);\n",
    "    let h2 = relu(h2_z);\n",
    "    let h3 = relu(h3_z);\n",
    "    \n",
    "    // Output layer\n",
    "    let out_z = h1 * w2_1 + h2 * w2_2 + h3 * w2_3 + b2;\n",
    "    let output = sigmoid(out_z);\n",
    "    \n",
    "    // Hidden activations\n",
    "    print(h1);\n",
    "    print(h2);\n",
    "    print(h3);\n",
    "    \n",
    "    // Output\n",
    "    print(output);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291bc694",
   "metadata": {},
   "source": [
    "## 4. Loss Functions\n",
    "\n",
    "Implement common loss functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "024eb4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='background:#f5f5f5; padding:10px; border-radius:5px; color:#000;'>Running: /home/codespace/.noma_jupyter/workspace/cell_7_a4652f41d9e2c4e4.noma\n",
       "[print] 0.03999999999999998\n",
       "[print] 0.09\n",
       "[print] 0.2231435513142097\n",
       "[print] 0.35667494393873245\n",
       "Result: 0\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Running: /home/codespace/.noma_jupyter/workspace/cell_7_a4652f41d9e2c4e4.noma\\n[print] 0.03999999999999998\\n[print] 0.09\\n[print] 0.2231435513142097\\n[print] 0.35667494393873245\\nResult: 0\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%noma\n",
    "fn mse_loss(pred, target) {\n",
    "    let error = pred - target;\n",
    "    return error * error;\n",
    "}\n",
    "\n",
    "fn bce_loss(pred, target) {\n",
    "    // Simplified BCE without clipping for demonstration\n",
    "    // In practice, predictions should be in (0,1) range\n",
    "    let term1 = target * log(pred);\n",
    "    let term2 = (1.0 - target) * log(1.0 - pred);\n",
    "    return -(term1 + term2);\n",
    "}\n",
    "\n",
    "fn main() {\n",
    "    let pred1 = 0.8;\n",
    "    let target1 = 1.0;\n",
    "    \n",
    "    let pred2 = 0.3;\n",
    "    let target2 = 0.0;\n",
    "    \n",
    "    // MSE results: (0.8-1.0)^2=0.04, (0.3-0.0)^2=0.09\n",
    "    print(mse_loss(pred1, target1));\n",
    "    print(mse_loss(pred2, target2));\n",
    "    \n",
    "    // BCE results\n",
    "    print(bce_loss(pred1, target1));\n",
    "    print(bce_loss(pred2, target2));\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d99cae7",
   "metadata": {},
   "source": [
    "## 5. Training Step (Forward Pass)\n",
    "\n",
    "Compute predictions and loss for a batch of examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ad8d0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='background:#f5f5f5; padding:10px; border-radius:5px; color:#000;'>Running: /home/codespace/.noma_jupyter/workspace/cell_8_c9932dca9b910dba.noma\n",
       "[print] 0.679178699175393\n",
       "[print] 0.7026606543447315\n",
       "[print] 0.5719961329315186\n",
       "[print] 0.38687100611489994\n",
       "[print] 0.35288121446099197\n",
       "[print] 0.8486230482344254\n",
       "[print] 0.5294584229367724\n",
       "Result: 0\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Running: /home/codespace/.noma_jupyter/workspace/cell_8_c9932dca9b910dba.noma\\n[print] 0.679178699175393\\n[print] 0.7026606543447315\\n[print] 0.5719961329315186\\n[print] 0.38687100611489994\\n[print] 0.35288121446099197\\n[print] 0.8486230482344254\\n[print] 0.5294584229367724\\nResult: 0\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%noma\n",
    "fn sigmoid(x) { \n",
    "    return 1.0 / (1.0 + exp(-x));\n",
    "}\n",
    "\n",
    "fn bce_loss(pred, target) {\n",
    "    // Simplified BCE without clipping\n",
    "    let term1 = target * log(pred);\n",
    "    let term2 = (1.0 - target) * log(1.0 - pred);\n",
    "    return -(term1 + term2);\n",
    "}\n",
    "\n",
    "fn network(x1, x2) {\n",
    "    let w1 = 0.5;\n",
    "    let w2 = 0.3;\n",
    "    let b = 0.1;\n",
    "    let z = x1 * w1 + x2 * w2 + b;\n",
    "    return sigmoid(z);\n",
    "}\n",
    "\n",
    "fn main() {\n",
    "    // Example 1: [1.0, 0.5] -> target 1.0\n",
    "    let pred1 = network(1.0, 0.5);\n",
    "    let loss1 = bce_loss(pred1, 1.0);\n",
    "    \n",
    "    // Example 2: [0.8, 1.2] -> target 1.0\n",
    "    let pred2 = network(0.8, 1.2);\n",
    "    let loss2 = bce_loss(pred2, 1.0);\n",
    "    \n",
    "    // Example 3: [0.2, 0.3] -> target 0.0\n",
    "    let pred3 = network(0.2, 0.3);\n",
    "    let loss3 = bce_loss(pred3, 0.0);\n",
    "    \n",
    "    // Average loss\n",
    "    let avg_loss = (loss1 + loss2 + loss3) / 3.0;\n",
    "    \n",
    "    // Results: predictions\n",
    "    print(pred1);\n",
    "    print(pred2);\n",
    "    print(pred3);\n",
    "    \n",
    "    // Results: individual losses\n",
    "    print(loss1);\n",
    "    print(loss2);\n",
    "    print(loss3);\n",
    "    \n",
    "    // Results: average\n",
    "    print(avg_loss);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af57e3f5",
   "metadata": {},
   "source": [
    "## 6. Gradient Descent Example\n",
    "\n",
    "Demonstrate gradient descent on a simple function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3532bef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='background:#f5f5f5; padding:10px; border-radius:5px; color:#000;'>Running: /home/codespace/.noma_jupyter/workspace/cell_12_0ff514a94e843364.noma\n",
       "[print] 0\n",
       "[print] 25\n",
       "[print] 0\n",
       "[print] 25\n",
       "[print] 1\n",
       "[print] 16\n",
       "[print] 1.8\n",
       "[print] 10.240000000000002\n",
       "[print] 2.4400000000000004\n",
       "[print] 6.553599999999998\n",
       "[print] 2.9520000000000004\n",
       "[print] 4.194303999999998\n",
       "[print] 3.3616\n",
       "[print] 2.6843545599999996\n",
       "[print] 3.68928\n",
       "[print] 1.7179869183999996\n",
       "[print] 3.9514240000000003\n",
       "[print] 1.0995116277759995\n",
       "[print] 4.1611392\n",
       "[print] 0.7036874417766399\n",
       "[print] 4.32891136\n",
       "[print] 0.4503599627370493\n",
       "[print] 4.4631290880000005\n",
       "[print] 0.2882303761517112\n",
       "[print] 4.570503270400001\n",
       "[print] 0.184467440737095\n",
       "[print] 4.65640261632\n",
       "[print] 0.11805916207174093\n",
       "[print] 4.725122093056\n",
       "[print] 0.07555786372591429\n",
       "[print] 4.7800976744448\n",
       "[print] 0.04835703278458515\n",
       "[print] 4.82407813955584\n",
       "[print] 0.030948500982134555\n",
       "[print] 4.859262511644672\n",
       "[print] 0.019807040628566166\n",
       "[print] 4.8874100093157375\n",
       "[print] 0.012676506002282305\n",
       "[print] 4.90992800745259\n",
       "[print] 0.008112963841460612\n",
       "[print] 4.90992800745259\n",
       "[print] 0.008112963841460612\n",
       "[print] 4.90992800745259\n",
       "[print] 0.008112963841460612\n",
       "Result: 0\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Running: /home/codespace/.noma_jupyter/workspace/cell_12_0ff514a94e843364.noma\\n[print] 0\\n[print] 25\\n[print] 0\\n[print] 25\\n[print] 1\\n[print] 16\\n[print] 1.8\\n[print] 10.240000000000002\\n[print] 2.4400000000000004\\n[print] 6.553599999999998\\n[print] 2.9520000000000004\\n[print] 4.194303999999998\\n[print] 3.3616\\n[print] 2.6843545599999996\\n[print] 3.68928\\n[print] 1.7179869183999996\\n[print] 3.9514240000000003\\n[print] 1.0995116277759995\\n[print] 4.1611392\\n[print] 0.7036874417766399\\n[print] 4.32891136\\n[print] 0.4503599627370493\\n[print] 4.4631290880000005\\n[print] 0.2882303761517112\\n[print] 4.570503270400001\\n[print] 0.184467440737095\\n[print] 4.65640261632\\n[print] 0.11805916207174093\\n[print] 4.725122093056\\n[print] 0.07555786372591429\\n[print] 4.7800976744448\\n[print] 0.04835703278458515\\n[print] 4.82407813955584\\n[print] 0.030948500982134555\\n[print] 4.859262511644672\\n[print] 0.019807040628566166\\n[print] 4.8874100093157375\\n[print] 0.012676506002282305\\n[print] 4.90992800745259\\n[print] 0.008112963841460612\\n[print] 4.90992800745259\\n[print] 0.008112963841460612\\n[print] 4.90992800745259\\n[print] 0.008112963841460612\\nResult: 0\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%noma\n",
    "fn loss_fn(x) {\n",
    "    let delta = x - 5.0;\n",
    "    return delta * delta;\n",
    "}\n",
    "\n",
    "fn main() {\n",
    "    // Use NOMA's declarative optimization syntax\n",
    "    learn x = 0.0;\n",
    "    \n",
    "    let loss = loss_fn(x);\n",
    "    \n",
    "    // Initial state\n",
    "    print(x);\n",
    "    print(loss);\n",
    "    \n",
    "    // Optimize x to minimize loss_fn(x)\n",
    "    optimize(x) until loss < 0.01 {\n",
    "        let loss = loss_fn(x);\n",
    "        minimize loss;\n",
    "    }\n",
    "    \n",
    "    // Final state after optimization\n",
    "    print(x);\n",
    "    print(loss_fn(x));\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7628cb1e",
   "metadata": {},
   "source": [
    "## 7. XOR Problem Setup\n",
    "\n",
    "The XOR problem is a classic test for neural networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3715ef1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='background:#f5f5f5; padding:10px; border-radius:5px; color:#000;'>Running: /home/codespace/.noma_jupyter/workspace/cell_6_7178597c7e195b4e.noma\n",
       "[print] 0.3775406687981454\n",
       "[print] 0.6224593312018546\n",
       "[print] 0.6224593312018546\n",
       "[print] 0.8175744761936437\n",
       "Result: 0\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Running: /home/codespace/.noma_jupyter/workspace/cell_6_7178597c7e195b4e.noma\\n[print] 0.3775406687981454\\n[print] 0.6224593312018546\\n[print] 0.6224593312018546\\n[print] 0.8175744761936437\\nResult: 0\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%noma\n",
    "fn sigmoid(x) { \n",
    "    return 1.0 / (1.0 + exp(-x));\n",
    "}\n",
    "\n",
    "fn simple_net(x1, x2) {\n",
    "    let w1 = 1.0;\n",
    "    let w2 = 1.0;\n",
    "    let b = -0.5;\n",
    "    let z = x1 * w1 + x2 * w2 + b;\n",
    "    return sigmoid(z);\n",
    "}\n",
    "\n",
    "fn main() {\n",
    "    // XOR inputs (simple network won't solve this)\n",
    "    print(simple_net(0.0, 0.0));\n",
    "    print(simple_net(0.0, 1.0));\n",
    "    print(simple_net(1.0, 0.0));\n",
    "    print(simple_net(1.0, 1.0));\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6d3b92",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "For more advanced topics, see:\n",
    "- `03_advanced.ipynb` - Caching, optimization, and Python integration\n",
    "- The main NOMA examples in `/workspaces/NOMA/examples/` for complete training loops"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
